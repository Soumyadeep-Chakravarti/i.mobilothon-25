# Dockerfile.gpu

# ----------------------------------------------------------------------
# BACKEND DOCKERFILE (GPU VERSION)
# Version: v1.4
# ----------------------------------------------------------------------
# Context:
#   - FastAPI backend with GPU-accelerated ML/CV tasks
#   - MongoDB (async), Celery + Redis integration
#   - Torch/TorchVision with CUDA runtime
#   - Fully aligned with Dockerfile.cpu for consistency
# ----------------------------------------------------------------------

# ======================================================================
# STAGE 1: BUILDER
# ======================================================================
FROM nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04 AS builder

LABEL maintainer="Team Alpha <team@projectdomain.com>" \
      version="v1.4" \
      description="Backend GPU Build - FastAPI + MongoDB + Celery + Redis (CUDA Accelerated)"

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

WORKDIR /app

# ----------------------------------------------------------------------
# 1️⃣ Install System Dependencies (Compilation, ML libs, etc.)
# ----------------------------------------------------------------------
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip python3-dev python3-venv \
    build-essential git wget curl ffmpeg \
    libsm6 libxext6 libgl1 \
    && rm -rf /var/lib/apt/lists/*

# ----------------------------------------------------------------------
# 2️⃣ Install Python Dependencies
# ----------------------------------------------------------------------
COPY app/requirements-gpu.txt ./requirements-gpu.txt

RUN python3 -m pip install --upgrade pip setuptools wheel \
    && pip install --no-cache-dir -r requirements-gpu.txt \
    && rm -rf /root/.cache/pip

# ----------------------------------------------------------------------
# STAGE 2: FINAL RUNTIME IMAGE
# Minimal runtime built from CUDA base for GPU inference
# ----------------------------------------------------------------------
FROM nvidia/cuda:12.1.1-cudnn8-runtime-ubuntu22.04 AS final

ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV PATH="/home/appuser/.local/bin:$PATH"

WORKDIR /app

# ----------------------------------------------------------------------
# 3️⃣ Install only runtime dependencies (minimal footprint)
# ----------------------------------------------------------------------
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip ffmpeg libsm6 libxext6 libgl1 curl \
    && apt-get clean && rm -rf /var/lib/apt/lists/*

# ----------------------------------------------------------------------
# 4️⃣ Copy installed Python dependencies and binaries from builder
# ----------------------------------------------------------------------
COPY --from=builder /usr/local/lib/python3.*/site-packages /usr/local/lib/python3.*/site-packages
COPY --from=builder /usr/local/bin /usr/local/bin

# ----------------------------------------------------------------------
# 5️⃣ Copy the application code, models, and entrypoint
# ----------------------------------------------------------------------
COPY app/src ./src
COPY models/ ./models/
COPY app/docker-entrypoint.sh .

RUN chmod +x docker-entrypoint.sh

# ----------------------------------------------------------------------
# 6️⃣ Security: Create non-root user
# ----------------------------------------------------------------------
RUN useradd -m appuser
USER appuser

# ----------------------------------------------------------------------
# 7️⃣ Healthcheck (Operational observability)
# ----------------------------------------------------------------------
HEALTHCHECK --interval=30s --timeout=5s --start-period=10s --retries=3 \
  CMD curl -f http://localhost:8000/health/liveness || exit 1

ENTRYPOINT ["/app/docker-entrypoint.sh"]
CMD ["web"]

